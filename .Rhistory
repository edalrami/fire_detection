library("ggplot2")
str(mtcars)
library("ggplot2")
mtcars %>%
geom_boxplot()
library("pracma")
library("ggplot2")
mtcars %>%
geom_boxplot()
mtcars %>%
ggplot(aes(factor(cyl), mpg)) +
geom_boxplot()
library("ggplot2")
mtcars %>%
ggplot(aes(factor(cyl), mpg)) +
geom_boxplot()
mtcars %>%
ggplot(aes(factor(cyl), mpg)) +
geom_boxplot()
mycars = data(mtcars)
mycars %>%
ggplot(aes(factor(cyl), mpg)) +
geom_boxplot()
library("ggplot2")
mycars = data(mtcars)
mycars %>%
ggplot(aes(factor(cyl), mpg)) +
geom_boxplot()
library("dplyr")
mycars = data(mtcars)
mycars %>%
ggplot(aes(factor(cyl), mpg)) +
geom_boxplot()
library("dplyr")
mtcars %>%
ggplot(aes(factor(cyl), mpg)) +
geom_boxplot()
mtcars %>%
ggplot(aes(factor(cyl), mpg, fill = factor(cyl))) +
geom_violin()+
geom_boxplot(width = 0.1)
library("stats")
mu = 26
popSigma = 1.4
n = 30
alpha = 0.05
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
plot(trueMu, power, `l`, xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
plot(trueMu, power, l, xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
#Same problem but alpha == 0.1
mu = 26
popSigma = 1.4
n = 30
alpha = 0.1
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
#Same problem but alpha == 0.1
mu = 26
popSigma = 1.4
n = 30
alpha = 0.01
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30"), col = "red", lwd = 3))
library("stats")
mu = 26
popSigma = 1.4
n = 30
alpha = 0.05
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
#Same problem but alpha == 0.1
mu1 = 26
popSigma1 = 1.4
n1 = 30
alpha1 = 0.01
c1 = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c1
trueMu1 = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta1 = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power1 = 1 - beta
plot(trueMu, power, 'l',
xlab = expression(mu),
main = "Power Curve", col = "red", lwd = 3)
lines(trueMu, power1, 'l',
xlab = expression(mu),
col = "green", lwd = 3)
legend(24.8, 0.8,
c("Sig level = 0.05", "Sig level = 0.01"),
lty = c(1,1),
lwd = c(2.5,2.5), col = c("red", "green"), cex = 0.5)
mu = 26
popSigma = 1.4
n = 30
alpha = 0.05
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
#Same problem but alpha == 0.1
mu1 = 26
popSigma1 = 1.4
n1 = 30
alpha1 = 0.01
c1 = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c1 = qnorm(alpha1, mean = mu1, sd = popSigma1/sqrt(n1))
c1
trueMu1 = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta1 = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power1 = 1 - beta
plot(trueMu, power, 'l',
xlab = expression(mu),
main = "Power Curve", col = "red", lwd = 3)
lines(trueMu, power1, 'l',
xlab = expression(mu),
col = "green", lwd = 3)
legend(24.8, 0.8,
c("Sig level = 0.05", "Sig level = 0.01"),
lty = c(1,1),
lwd = c(2.5,2.5), col = c("red", "green"), cex = 0.5)
library("stats")
mu = 26
popSigma = 1.4
n = 30
alpha = 0.05
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
#Same problem but alpha == 0.1
mu1 = 26
popSigma1 = 1.4
n1 = 30
alpha1 = 0.01
c1 = qnorm(alpha1, mean = mu1, sd = popSigma1/sqrt(n1))
c1
trueMu1 = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta1 = 1 - pnorm(c, mean = trueMu1, sd = popSigma1/sqrt(n1))
power1 = 1 - beta1
plot(trueMu, power, 'l',
xlab = expression(mu),
main = "Power Curve", col = "red", lwd = 3)
lines(trueMu, power1, 'l',
xlab = expression(mu),
col = "green", lwd = 3)
legend(24.8, 0.8,
c("Sig level = 0.05", "Sig level = 0.01"),
lty = c(1,1),
lwd = c(2.5,2.5), col = c("red", "green"), cex = 0.5)
library("stats")
mu = 26
popSigma = 1.4
n = 30
alpha = 0.05
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
#plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
#Same problem but alpha == 0.1
mu1 = 26
popSigma1 = 1.4
n1 = 30
alpha1 = 0.01
c1 = qnorm(alpha1, mean = mu1, sd = popSigma1/sqrt(n1))
c1
trueMu1 = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta1 = 1 - pnorm(c1, mean = trueMu1, sd = popSigma1/sqrt(n1))
power1 = 1 - beta1
plot(trueMu, power, 'l',
xlab = expression(mu),
main = "Power Curve", col = "red", lwd = 3)
lines(trueMu, power1, 'l',
xlab = expression(mu),
col = "green", lwd = 3)
legend(24.8, 0.8,
c("Sig level = 0.05", "Sig level = 0.01"),
lty = c(1,1),
lwd = c(2.5,2.5), col = c("red", "green"), cex = 0.5)
d = c(7.2,7.3,6.1,6.9,6.6,7.3,6.3,5.5,6.3,6.5,5.7,6.9,6.7,7.9,5.8)
alpha = 0.05
mean = 6.5
d = c(7.2,7.3,6.1,6.9,6.6,7.3,6.3,5.5,6.3,6.5,5.7,6.9,6.7,7.9,5.8)
n = length(d)
delta = 0.5
alpha = 0.05
mean = 6.5
d = c(7.2,7.3,6.1,6.9,6.6,7.3,6.3,5.5,6.3,6.5,5.7,6.9,6.7,7.9,5.8)
n = length(d)
#difference between truemu and hypothesis
delta = 0.5
s = sd(d)
power.t.test(n, delta, sd =s, sig.level = alpha, power = NULL, type = "one.sample", alternative = "one.sided")
power.t.test(n = NULL, delta, sd = 0.5, sig.level = alpha, power = 0.95, type = "one.sample", alternative = "one.sided")
power.t.test(n = NULL, delta, sd = s, sig.level = alpha, power = 0.95, type = "one.sample", alternative = "one.sided")
food = c(143,138,169,152,149,150,135,141,161,159)
library("dplyr")
d %>%
ggplot(aes(x="", y = cost))+
geom_jitter(shape = 23, position = position_jitter(0.2), color = "red")+
geom_boxplot(width = 0.1)
library("dplyr")
library("ggplot2")
d %>%
ggplot(aes(x="", y = cost))+
geom_jitter(shape = 23, position = position_jitter(0.2), color = "red")+
geom_boxplot(width = 0.1)
d = data.frame(cost = c(143,138,169,152,149,150,135,141,161,159))
d %>%
ggplot(aes(x="", y = cost))+
geom_jitter(shape = 23, position = position_jitter(0.2), color = "red")+
geom_boxplot(width = 0.1)
d$cost %>%
wilcox.test(mu = 157, alternative = "less")
d = data.frame(cost = c(143,138,169,152,149,150,85,141,161,159))
library("dplyr")
library("ggplot2")
d %>%
ggplot(aes(x="", y = cost))+
geom_jitter(shape = 23, position = position_jitter(0.2), color = "red")+
geom_boxplot(width = 0.1)
d$cost %>%
wilcox.test(mu = 157, alternative = "less")
alpha = 0.05
mean = 6.5
d = c(7.2,7.3,6.1,6.9,6.6,7.3,6.3,5.5,6.3,6.5,5.7,6.9,6.7,7.9,5.8)
n = length(d)
#difference between truemu and hypothesis
delta = 0.5
s = sd(d)
#assuming power is null
power.t.test(n, delta, sd =s, sig.level = alpha, power = NULL, type = "one.sample", alternative = "one.sided")
#assuming power is null
t.test(n, delta, sd =s, sig.level = alpha, power = NULL, type = "one.sample", alternative = "one.sided")
#assuming power is null
power.t.test(n, delta, sd =s, sig.level = alpha, power = NULL, type = "one.sample", alternative = "one.sided")
t.test(d, alternative = "greater", mu = 6, conf.level = 0.95)
install.packages("BSDA")
knitr::opts_chunk$set(echo = TRUE)
dim(samples)
mu = 16.7
sd = 6
n = 100
alpha = 0.05
trueMu = 15.5
z = (trueMu - mu)/(sd/sqrt(n))
z
#calculate P
#probability of getting data at least as inconsistent with null
#hypothesis
P = 2*pnorm(z)
P
#calculate probability of getting type II Error
x_right = qnorm(alpha/2, mean = 16.7, sd = 6/sqrt(100), lower.tail = F)
x_left = qnorm(alpha/2, mean = 16.7, sd = 6/sqrt(100), lower.tail = T)
x_right
x_left
(beta = pnorm(x_right, mean = 15.5, sd = 6/sqrt(100), lower.tail = T) - pnorm(x_left, mean = 15.5, sd = 6/sqrt(100), lower.tail = T))
#Each row of samples is a sample size of 100 from the standard
#normal distribution with a mean of 16.7 and a standard deviation
#of 6.
set.seed(124)
samples <- matrix(rnorm(100000, 16.7, 6), 1000, 100)
head(samples)
dim(samples)
sample_means = rowMeans(samples)
length(sample_means)
count(sample_means, vars = 16.7)
count(sample_means, vars = '16.7')
count = as.data.frame(table(sample_means))
count
frequencies = as.data.frame(table(round(sample_means, 1)))
frequencies[frequencies.Var1 == 16.7]
frequencies[frequencies$Var1 == 16.7]
frequencies = as.data.frame(table(round(sample_means, 1)))
frequencies[frequencies$Var1 == 16.7]
colnames(frequencies)
frequencies[frequencies$Var1 == 16.7,]
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
result = count/length(sample_means)
result
frequencies = as.data.frame(table(signif(sample_means, 2)))
colnames(frequencies)
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
as.numeric( format(13.7, nsmall = 2))
frequencies = as.data.frame(table(as.numeric(format(sample_means, nsmall = 2))))
colnames(frequencies)
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
result = count/length(sample_means)*100
result
frequencies = as.data.frame(table(sample_means))
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
result = count/length(sample_means)*100
result
frequencies = as.data.frame(table(sample_means))
colnames(frequencies)
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
sample_means = noquote(format(sample_means, digits = 3))
frequencies = as.data.frame(table(sample_means))
colnames(frequencies)
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
sample_means = rowMeans(samples)
length(sample_means)
sample_means = noquote(format(sample_means, digits = 3))
frequencies = as.data.frame(table(sample_means))
colnames(frequencies)
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
result = count/length(sample_means)*100
result
set.seed(124)
#Generate 100,000 random numbers from a standard normal distribution
#with a mean of 16.7 and standard deviation of 6.
#Organize results into 1000x100 matrix.
samples <- matrix(rnorm(100000, 16.7, 6), 1000, 100)
head(samples)
head(samples)
dim(samples)
frequencies = as.data.frame(table(sample_means))
colnames(frequencies)
count = frequencies[frequencies$Var1 == 16.7,]$Freq
count
set.seed(124)
#Generate 100,000 random numbers from a standard normal distribution
#with a mean of 16.7 and standard deviation of 6.
#Organize results into 1000x100 matrix.
samples <- matrix(rnorm(100000, 16.7, 6), 1000, 100)
#head(samples)
dim(samples)
sample_means = rowMeans(samples)
length(sample_means)
frequencies = as.data.frame(table(sample_means))
colnames(frequencies)
head(frequencies)
frequencies = as.data.frame(table(sample_means))
set.seed(124)
#Generate 100,000 random numbers from a standard normal distribution
#with a mean of 16.7 and standard deviation of 6.
#Organize results into 1000x100 matrix.
samples <- matrix(rnorm(100000, 16.7, 6), 1000, 100)
#head(samples)
dim(samples)
sample_means = rowMeans(samples)
set.seed(124)
knitr::opts_chunk$set(echo = TRUE)
frequency = as.data.frame(table(noquote(format(sample_means, digits = 3))))
frequency = as.data.frame(table(noquote(format(sample_means, digits = 3))))
library("BSDA")
str(Anxiety)
attach(Anxiety)
m = lm(math~anxiety)
plot(anxiety, math)
abline(m)
library("stats")
cook = cooks.distance(m)
plot(cook, ylab = "Cook's Distance")
Anxiety[which(cook > 1),]
library("stats")
mu = 26
popSigma = 1.4
n = 30
alpha = 0.05
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
#Same problem but alpha == 0.1
mu1 = 26
popSigma1 = 1.4
n1 = 30
alpha1 = 0.01
c1 = qnorm(alpha1, mean = mu1, sd = popSigma1/sqrt(n1))
c1
trueMu1 = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta1 = 1 - pnorm(c1, mean = trueMu1, sd = popSigma1/sqrt(n1))
power1 = 1 - beta1
plot(trueMu, power, 'l',
xlab = expression(mu),
main = "Power Curve", col = "red", lwd = 3)
library("stats")
mu = 26
popSigma = 1.4
n = 30
alpha = 0.05
c = qnorm(alpha, mean = mu, sd = popSigma/sqrt(n))
c
trueMu = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta = 1 - pnorm(c, mean = trueMu, sd = popSigma/sqrt(n))
power = 1 - beta
#plot(trueMu, power, 'l', xlab = expression(mu), main = expression(paste("Power Curve (", alpha , " = 0.5, n = 30")))
#Same problem but alpha == 0.1
mu1 = 26
popSigma1 = 1.4
n1 = 30
alpha1 = 0.01
c1 = qnorm(alpha1, mean = mu1, sd = popSigma1/sqrt(n1))
c1
trueMu1 = seq(24.8, 25.9, by = 0.1)
#pnorm is cdf
beta1 = 1 - pnorm(c1, mean = trueMu1, sd = popSigma1/sqrt(n1))
power1 = 1 - beta1
plot(trueMu, power, 'l',
xlab = expression(mu),
main = "Power Curve", col = "red", lwd = 3)
lines(trueMu, power1, 'l',
xlab = expression(mu),
col = "green", lwd = 3)
legend(24.8, 0.8,
c("Sig level = 0.05", "Sig level = 0.01"),
lty = c(1,1),
lwd = c(2.5,2.5), col = c("red", "green"), cex = 0.5)
alpha = 0.05
mean = 6.5
d = c(7.2,7.3,6.1,6.9,6.6,7.3,6.3,5.5,6.3,6.5,5.7,6.9,6.7,7.9,5.8)
n = length(d)
#difference between truemu and hypothesis
delta = 0.5
s = sd(d)
#assuming power is null
power.t.test(n, delta, sd =s, sig.level = alpha, power = NULL, type = "one.sample", alternative = "one.sided")
t.test(d, alternative = "greater", mu = 6, conf.level = 0.95)
#how large of a data set do you need in order to detect
#a deviation of 0.5 from the true mean with the power of 0.95?
power.t.test(n = NULL, delta, sd = s, sig.level = alpha, power = 0.95, type = "one.sample", alternative = "one.sided")
d = data.frame(cost = c(143,138,169,152,149,150,85,141,161,159))
library("dplyr")
library("ggplot2")
d %>%
ggplot(aes(x="", y = cost))+
geom_jitter(shape = 23, position = position_jitter(0.2), color = "red")+
geom_boxplot(width = 0.1)
d$cost %>%
wilcox.test(mu = 157, alternative = "less")
d = read.csv("Orion.csv")
m = lm(d$Price ~ d$Age)
confint(m, level = 0.95)
library("stats")
library("stats")
library("BSDA")
attach("Anxiety")
attach(Anxiety)
m = lm(math~anxiety)
plot(anxiety,math)
abline(m)
summary(m)$r.squared
dResid = resid(m)
x <- c(12,10,9,3,4,3)
x[x==3]<-4
x
x <- c(12,10,9,3,4,3)
x[x=3]<-4
x
x <- c(12,10,9,3,4,3)
x <- c(12,10,9,3,4,3)
x[x=4]<-3
x
x <- c(12,10,9,3,4,3)
x[x==4]<-3
x
7/0
v <- c(2,5,6,6,9)
t <- c(8,2,5,14,9)
(v == t)
v <- c(2,5.6,6,9)
t <- c(8,2.5,14,9)
(v == t)
v[which.min(v)]
setwd("C:/Users/edalr/Desktop/school/researchmethods/final/fire_detection")
install.packages("rticles")
